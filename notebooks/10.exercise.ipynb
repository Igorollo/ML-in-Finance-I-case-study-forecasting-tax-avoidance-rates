{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Instructions: Panel Data Modeling with Machine Learning Models\n",
    "\n",
    "**Objective:**\n",
    "The goal of this exercise is to practice panel data modeling skills using three machine learning models (Random Forest, Single Decision Tree, and Linear Regression with Elastic Net) that have not been utilized in the project so far. Completing the entire task or a significant portion during the class will earn you an additional 7 points (above what is outlined in the syllabus) towards your final grade.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. **GitHub Setup:**\n",
    "   - If you haven't done so already, [create](https://github.com/join) a GitHub account.\n",
    "   - [Download](https://desktop.github.com) and [configure](https://docs.github.com/en/desktop/configuring-and-customizing-github-desktop/configuring-basic-settings-in-github-desktop) GitHub Desktop on your laptop. (Here you can find nice intro to the GitHub Dekstop app: [link](https://joshuadull.github.io/GitHub-Desktop/02-getting-started/index.html)). If you prefare git command line usage you can go with this [instruction](https://github.com/michaelwozniak/ml2_tools?tab=readme-ov-file#git).\n",
    "2. **Repository Forking:**\n",
    "   - [Fork](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/fork-a-repo) the following repository to your projects: [https://github.com/michaelwozniak/ML-in-Finance-I-case-study-forecasting-tax-avoidance-rates](https://github.com/michaelwozniak/ML-in-Finance-I-case-study-forecasting-tax-avoidance-rates)\n",
    "\n",
    "3. **Repository Cloning:**\n",
    "   - [Clone](https://docs.github.com/en/desktop/adding-and-cloning-repositories/cloning-a-repository-from-github-to-github-desktop) the forked repository to your local computer using GitHub Desktop.\n",
    "\n",
    "4. **Notebook Exploration:**\n",
    "   - Open the file `notebooks/10.exercise.ipynb` to begin the ML tasks.\n",
    "\n",
    "5. **Model Creation:**\n",
    "\n",
    "   In the file `notebooks/10.exercise.ipynb`:\n",
    "   - Create the following models:\n",
    "      1. Random Forest ([RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html))\n",
    "      2. Decision Tree ([DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html))\n",
    "      3. Linear Regression with Elastic Net ([ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html))\n",
    "   \n",
    "   Follow a similar process to the models presented in class (e.g., KNN - `notebooks/07.knn-model.ipynb`):\n",
    "      - Load the prepared training data.\n",
    "      - Perform feature engineering if deemed necessary (note: these three models do not require data standardization, unlike SVM and KNN).\n",
    "      - Conduct feature selection.\n",
    "      - Perform hyperparameter tuning.\n",
    "      - Identify a local champion for each model class (the best model for RF, DT, Elastic Net).\n",
    "      - Save local champions to a pickle file.\n",
    "\n",
    "6. **Model Evaluation:**\n",
    "   - In the notebook `notebooks/09.final-comparison-and-summary.ipynb`, load the models you created and check if they outperform the previously used models.\n",
    "\n",
    "7. **Version Control:**\n",
    "   - At the end of the class, even if the tasks are incomplete, [commit](https://docs.github.com/en/desktop/making-changes-in-a-branch/committing-and-reviewing-changes-to-your-project-in-github-desktop) your changes using GitHub Desktop.\n",
    "   - [Push](https://docs.github.com/en/desktop/making-changes-in-a-branch/pushing-changes-to-github-from-github-desktop) your changes to your remote GitHub repository.\n",
    "\n",
    "8. **Submission:**\n",
    "   - Send me the link to your GitHub project (my email: *mj.wozniak9@uw.edu.pl*).\n",
    "\n",
    "Good luck with the exercise! If you have any questions, feel free to ask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble   import RandomForestRegressor\n",
    "from sklearn.tree       import DecisionTreeRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.model_selection import (GridSearchCV, TimeSeriesSplit,\n",
    "                                     train_test_split)\n",
    "from sklearn.metrics      import mean_squared_error, make_scorer\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline    import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 1.6.1\n",
      "Python executable: /Users/igor/Downloads/ML_dod1/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sklearn, sys\n",
    "print(\"sklearn:\", sklearn.__version__)\n",
    "print(\"Python executable:\", sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR   = Path(\"../data/output\")\n",
    "MODEL_DIR  = Path(\"../models\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df   = pd.read_csv(DATA_DIR / \"train_fe.csv\", index_col=0)\n",
    "rank = pd.read_excel(DATA_DIR / \"feature_ranking.xlsx\", index_col=0)\n",
    "\n",
    "TARGET = \"etr\"\n",
    "df     = df.sort_values(\"rok\").reset_index(drop=True)\n",
    "X, y   = df.drop(columns=TARGET), df[TARGET]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = [\n",
    "    \"ta\",\n",
    "    \"txt\",\n",
    "    \"pi\",\n",
    "    \"str\",\n",
    "    \"xrd\",\n",
    "    \"ni\",\n",
    "    \"ppent\",\n",
    "    \"intant\",\n",
    "    \"dlc\",\n",
    "    \"dltt\",\n",
    "    \"capex\",\n",
    "    \"revenue\",\n",
    "    \"cce\",\n",
    "    \"adv\",\n",
    "    \"diff\",\n",
    "    \"roa\",\n",
    "    \"lev\",\n",
    "    \"intan\",\n",
    "    \"rd\",\n",
    "    \"ppe\",\n",
    "    \"sale\",\n",
    "    \"cash_holdings\",\n",
    "    \"adv_expenditure\",\n",
    "    \"capex2\",\n",
    "    \"cfc\",\n",
    "    \"dta\",\n",
    "    \"y_v2x_polyarchy\",\n",
    "    \"WB_GDPgrowth\",\n",
    "    \"WB_GDPpc\",\n",
    "    \"WB_Inflation\",\n",
    "    \"rr_per_country\",\n",
    "    \"rr_per_sector\",\n",
    "    \"etr_y_past\",\n",
    "    \"etr_y_ma\",\n",
    "    \"diff_ma\",\n",
    "    \"roa_ma\",\n",
    "    \"lev_ma\",\n",
    "    \"intan_ma\",\n",
    "    \"ppe_ma\",\n",
    "    \"sale_ma\",\n",
    "    \"cash_holdings_ma\",\n",
    "    \"roa_past\",\n",
    "    \"lev_past\",\n",
    "    \"intan_past\",\n",
    "    \"ppe_past\",\n",
    "    \"sale_past\",\n",
    "    \"cash_holdings_past\",\n",
    "]           \n",
    "mi_features_35  = rank.iloc[:35].index.tolist()\n",
    "\n",
    "tree_feats = rank.sort_values(\"mi_score\", ascending=False).iloc[:60].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=6, test_size=363)\n",
    "\n",
    "SCORER = \"neg_root_mean_squared_error\"\n",
    "\n",
    "def train_champion(model_name: str,\n",
    "                   base_estimator,\n",
    "                   param_grid: dict,\n",
    "                   feature_candidates,\n",
    "                   scale=False):\n",
    "\n",
    "    steps = []\n",
    "    if scale:\n",
    "        steps.append((\"sc\", StandardScaler()))\n",
    "    steps.append((\"model\", base_estimator))\n",
    "    pipe = Pipeline(steps)\n",
    "\n",
    "    search = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid={f\"model__{k}\": v for k, v in param_grid.items()},\n",
    "        cv=5,\n",
    "        scoring=SCORER,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    search.fit(X[feature_candidates], y)\n",
    "    best_pipe = search.best_estimator_\n",
    "\n",
    "    if isinstance(base_estimator, (RandomForestRegressor, DecisionTreeRegressor)):\n",
    "        fs = RFECV(\n",
    "            estimator=best_pipe,\n",
    "            step=1,\n",
    "            cv=5,\n",
    "            scoring=SCORER,\n",
    "            n_jobs=-1,\n",
    "            importance_getter=\"named_steps.model.feature_importances_\",\n",
    "        )\n",
    "    else:                                         \n",
    "        fs = SelectFromModel(\n",
    "            estimator=best_pipe.named_steps[\"model\"],\n",
    "            prefit=True,\n",
    "            threshold=\"median\",\n",
    "        )\n",
    "    fs.fit(X[feature_candidates], y)\n",
    "    selected_feats = X[feature_candidates].columns[fs.get_support()]\n",
    "\n",
    "    cv_val = []\n",
    "    for tr_idx, te_idx in tscv.split(X):\n",
    "        best_pipe.fit(X.iloc[tr_idx][selected_feats], y.iloc[tr_idx])\n",
    "        preds = best_pipe.predict(X.iloc[te_idx][selected_feats])\n",
    "        cv_val.append(mean_squared_error(y.iloc[te_idx], preds))\n",
    "    \n",
    "    mean_rmse, std_rmse = np.mean(cv_val), np.std(cv_val)\n",
    "\n",
    "    best_pipe.fit(X[selected_feats], y)\n",
    "    pickle.dump(best_pipe, open(MODEL_DIR / f\"{model_name}.sav\", \"wb\"))\n",
    "\n",
    "    print(f\"{model_name}: {mean_rmse:.4f} ± {std_rmse:.4f}  |  {len(selected_feats)} feats\")\n",
    "    return mean_rmse, std_rmse, best_pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = dict(\n",
    "    n_estimators =[200, 500, 800],\n",
    "    max_depth    =[None, 10, 20, 30],\n",
    "    min_samples_leaf=[1, 3, 5],\n",
    "    max_features =[\"sqrt\", \"log2\", .5]\n",
    ")\n",
    "\n",
    "dt_grid = dict(\n",
    "    max_depth       =[None, 5, 10, 20, 30],\n",
    "    min_samples_leaf=[1, 3, 5, 10],\n",
    "    min_samples_split=[2, 5, 10]\n",
    ")\n",
    "\n",
    "en_grid = dict(\n",
    "    alpha =[0.01, 0.1, 1, 5, 10],\n",
    "    l1_ratio=[.1, .3, .5, .7, .9, 1.0],\n",
    "    max_iter=[5000]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: 0.0198 ± 0.0034  |  56 feats\n",
      "dt: 0.0214 ± 0.0040  |  3 feats\n",
      "elastic: 0.0221 ± 0.0029  |  35 feats\n"
     ]
    }
   ],
   "source": [
    "rf_score = train_champion(\"rf\",\n",
    "                          RandomForestRegressor(random_state=0, n_jobs=-1),\n",
    "                          rf_grid,\n",
    "                          tree_feats,    \n",
    "                          scale=False)\n",
    "\n",
    "dt_score = train_champion(\"dt\",\n",
    "                          DecisionTreeRegressor(random_state=0),\n",
    "                          dt_grid,\n",
    "                          tree_feats,\n",
    "                          scale=False)\n",
    "\n",
    "en_score = train_champion(\"elastic\",\n",
    "                          ElasticNet(),\n",
    "                          en_grid,\n",
    "                          mi_features_35,   \n",
    "                          scale=True)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
